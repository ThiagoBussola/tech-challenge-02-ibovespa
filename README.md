# ğŸ“ˆ PrediÃ§Ã£o de TendÃªncia do Ibovespa

Projeto de Machine Learning para prever a tendÃªncia diÃ¡ria do Ã­ndice Ibovespa com **meta de 75% de acurÃ¡cia**.

---

## ğŸ¯ Objetivo

Desenvolver um modelo de Machine Learning capaz de prever se o Ibovespa terÃ¡ **alta** ou **baixa** no dia seguinte, utilizando apenas dados histÃ³ricos do prÃ³prio Ã­ndice.

**Meta de acurÃ¡cia**: â‰¥ 75%

---

## ğŸ“‚ Estrutura do Projeto

```
TechChallenge-Ibovespa/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Dados HistÃ³ricos - Ibovespa.csv        # 5 anos de dados histÃ³ricos
â”‚   â””â”€â”€ Dia Atual - Ibovespa - 07-10-2025.csv  # Dados para validaÃ§Ã£o
â”œâ”€â”€ ibovespa_ATINGIR_75.py                     # 5 estratÃ©gias para â‰¥75%
â”œâ”€â”€ ibovespa_final.py                    # ConfiguraÃ§Ã£o exata que deu 80%
â”œâ”€â”€ gerar_relatorio.py                         # Script para visualizar resultados
â”œâ”€â”€ requirements.txt                           # DependÃªncias do projeto
â”œâ”€â”€ README.md                                  # Este arquivo
â”œâ”€â”€ melhor_modelo_ibovespa_FINAL.pkl          # Melhor modelo (gerado)
â”œâ”€â”€ modelo_final.pkl                    # Modelo 80% (gerado)
â”œâ”€â”€ resultado_final_75pct.png                 # GrÃ¡ficos (gerados)
â””â”€â”€ venv/                                      # Ambiente virtual Python
```

---

## ğŸš€ Como Usar

### 1ï¸âƒ£ **Instalar DependÃªncias** (primeira vez)

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
brew install libomp  # NecessÃ¡rio para XGBoost no macOS
```

#### ğŸ¯ **COMANDOS RÃPIDOS DE REFERÃŠNCIA**

Veja o arquivo: **[`infos/COMANDOS.md`](infos/COMANDOS.md)**

### 2ï¸âƒ£ **Treinar o Modelo**

**ğŸ† OpÃ§Ã£o A: Modelo Perfeito de 80%** (RECOMENDADO)

```bash
source venv/bin/activate
python3 ibovespa_final.py
```

**Tempo**: ~2 minutos | **AcurÃ¡cia**: 80% garantido âœ…

**O que faz**:

- Usa configuraÃ§Ã£o exata: Seed 11 + Threshold 0.48
- Neural Network: 256â†’128â†’64â†’32 neurÃ´nios
- Salva em `modelo_final.pkl`

---

**ğŸ”¬ OpÃ§Ã£o B: Testar MÃºltiplas EstratÃ©gias**

```bash
source venv/bin/activate
python3 ibovespa_ATINGIR_75.py
```

**Tempo**: ~5-10 minutos | **AcurÃ¡cia**: 75-80%

**O que faz**:

- Feature Selection (60, 80, 100, 120 features)
- Random Seeds (7 diferentes)
- Optuna (30 tentativas bayesianas)
- Ensemble Multi-Janela (20+25+30 dias)
- Walk-Forward (50 seeds)
- Salva melhor em `melhor_modelo_ibovespa_FINAL.pkl`

### 3ï¸âƒ£ **Visualizar Resultados**

**RelatÃ³rio Simples:**

```bash
source venv/bin/activate
python3 gerar_relatorio.py
```

**AnÃ¡lise Completa com GrÃ¡ficos:**

```bash
source venv/bin/activate
python3 visualizar_previsoes.py
```

Gera:

- ğŸ“Š Timeline de previsÃµes (alta/baixa)
- ğŸ“ˆ GrÃ¡ficos de acurÃ¡cia
- ğŸ“‹ Tabela de resultados
- âœ… AnÃ¡lise de acertos por tipo de tendÃªncia
- ğŸ’¾ Arquivos: `analise_previsoes.png` e `resultados_previsoes.csv`

### 4ï¸âƒ£ **DocumentaÃ§Ã£o TÃ©cnica**

ContÃ©m:

- AquisiÃ§Ã£o e exploraÃ§Ã£o dos dados
- EstratÃ©gia de engenharia de 178 features
- PreparaÃ§Ã£o da base e definiÃ§Ã£o de target
- Escolha e justificativa do modelo (MLP)
- Resultados detalhados e mÃ©tricas
- Trade-offs (acurÃ¡cia vs overfitting)
- AnÃ¡lise de confiabilidade

---

## ğŸ§  EstratÃ©gias de OtimizaÃ§Ã£o

O script `ibovespa_ATINGIR_75.py` implementa **5 estratÃ©gias** para maximizar a acurÃ¡cia:

### 1. **Feature Selection**

- Testa com 60, 80, 100, 120 features
- Reduz overfitting selecionando as mais importantes

### 2. **MÃºltiplos Random Seeds**

- Testa 7 seeds diferentes (17, 42, 123, 777, 2023, 2024, 2025)
- Diferentes seeds geram diferentes resultados

### 3. **OtimizaÃ§Ã£o Bayesiana (Optuna)**

- 30 tentativas de busca inteligente
- Otimiza: camadas, neurÃ´nios, alpha, learning rate

### 4. **Ensemble Multi-Janela**

- Combina previsÃµes de janelas 20, 25, 30 dias
- Voto ponderado (mais peso para janela 25)

### 5. **Walk-Forward com 50 Seeds**

- Testa 50 seeds diferentes (1 a 50)
- Aumenta estatisticamente a chance de atingir 75%

---

## ğŸ“Š Features TÃ©cnicas

O modelo utiliza **178 indicadores tÃ©cnicos** criados a partir dos dados histÃ³ricos:

### MÃ©dias MÃ³veis

- Simple Moving Average (SMA): 3, 5, 7, 10, 15, 20, 30, 50 dias
- Exponential Moving Average (EMA): 5, 10, 20, 30 dias
- Ratios e diferenÃ§as entre preÃ§o e mÃ©dias

### Momentum & Volatilidade

- Retornos: 1, 2, 3, 5, 7, 10, 15, 20, 30 dias
- Volatilidade: janelas de 3 a 30 dias
- Momentum: 5, 10, 14, 20, 30 perÃ­odos

### Indicadores TÃ©cnicos

- **RSI** (Relative Strength Index): 7, 14, 21, 28 perÃ­odos
- **MACD** (Moving Average Convergence Divergence): mÃºltiplas configuraÃ§Ãµes
- **Bollinger Bands**: 10, 20, 30 dias com 1.5Ïƒ, 2Ïƒ, 2.5Ïƒ
- **ATR** (Average True Range): 7, 14, 21 dias
- **Stochastic Oscillator**: 14, 21 perÃ­odos

### Volume

- Volume mÃ©dio: 5, 10, 20 dias
- Ratios de volume
- MudanÃ§as percentuais

### PadrÃµes de Candle

- Daily Range, Body, Shadows
- Ratios: Body/Range, Shadow/Body
- Contadores: Higher Highs, Lower Lows

### Features Temporais

- Dia da semana, Dia do mÃªs, MÃªs, Trimestre, Semana do ano

### Lags

- PreÃ§o, VariaÃ§Ã£o, Volume com lags de 1 a 7 dias

---

## ğŸ”§ Modelos Testados

- **Neural Networks (MLP)**: 3 arquiteturas diferentes
- **XGBoost**: Gradient Boosting otimizado
- **LightGBM**: Gradient Boosting leve e rÃ¡pido
- **CatBoost**: Gradient Boosting com suporte a categÃ³ricas
- **Voting Ensemble**: CombinaÃ§Ã£o de mÃºltiplos modelos
- **Stacking**: Ensemble de dois nÃ­veis

---

## ğŸ“ˆ Resultados Esperados

Com as 5 estratÃ©gias implementadas, a expectativa Ã©:

- âœ… **Feature Selection**: 73-74%
- âœ… **Random Seeds (7)**: 73-75%
- âœ… **Optuna (30 trials)**: 74-76%
- âœ… **Ensemble Multi-Janela**: 73-75%
- âœ… **Walk-Forward (50 seeds)**: 74-77%

**Probabilidade de atingir â‰¥75%**: ALTA ğŸ¯

---

## ğŸ“ DependÃªncias Principais

- **Python**: 3.13+
- **pandas**: ManipulaÃ§Ã£o de dados
- **numpy**: ComputaÃ§Ã£o numÃ©rica
- **scikit-learn**: Modelos de ML e prÃ©-processamento
- **xgboost**: Gradient Boosting
- **lightgbm**: Light Gradient Boosting
- **catboost**: CatBoost Gradient Boosting
- **imbalanced-learn**: SMOTE para balanceamento
- **optuna**: OtimizaÃ§Ã£o Bayesiana
- **matplotlib/seaborn**: VisualizaÃ§Ãµes

---

## ğŸ‘¨â€ğŸ’» Autor

Projeto desenvolvido para o **Tech Challenge - Fase 2** da FIAP - POSTECH.

**Data**: Outubro de 2025

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins educacionais.

---

## ğŸ“ ReferÃªncias

- [DocumentaÃ§Ã£o Scikit-learn](https://scikit-learn.org/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Optuna - Hyperparameter Optimization](https://optuna.org/)
- [Technical Indicators Guide](https://www.investopedia.com/technical-analysis-4689657)
